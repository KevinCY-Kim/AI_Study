# -*- coding: utf-8 -*-
"""데이콘_Basic_고객_지원_등급_분류.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nveayOGk1TPBvyrbNQs4oulsVjjZstEQ

<a href="https://colab.research.google.com/github/KevinCY-Kim/AI_Study/blob/main/%EB%8D%B0%EC%9D%B4%EC%BD%98_Basic_%EA%B3%A0%EA%B0%9D_%EC%A7%80%EC%9B%90_%EB%93%B1%EA%B8%89_%EB%B6%84%EB%A5%98.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## 1. 연속형 vs 연속형 일때는 피어슨 상관계수를 쓴다. label이 명목형일때는 연관성을 어떻게 측정하는지 고찰
스피어만 상관계수, 피어슨 상관계수가 뭔지 알아보자

-  명목형 vs 명목형: 카이제곱 통계량($\chi^2$) 및 연관성 척도(Cramér's V 등)를 사용하여 교차표의 관측 빈도 차이를 분석합니다.
-  명목형 vs 연속형: 명목형 변수의 각 범주에 따른 연속형 변수의 평균 차이를 검정하는 **ANOVA(분산분석)**를 주로 사용합니다.
-  명목형 변수가 **이진(Binary)**인 경우에 한해 Point-Biserial Correlation을 사용하기도 합니다.
-  궁극적으로 명목형 변수는 더미 변수로 변환되어 모델에 투입됩니다.

### 피어슨 상관계수 (Pearson Correlation Coefficient, $r$)
-	피어슨 상관계수는 두 변수 $X$와 $Y$ 간의 선형적 관계의 강도와 방향을 측정하는 가장 일반적인 통계 지표입니다.
-	원인 및 사용 조건: 두 변수가 모두 **연속형 데이터(등간척도 또는 비율척도)**이고, 이들 관계가 직선 형태의 선형성을 보이며, 데이터가 정규 분포를 따른다고 가정하는 모수적 방법일 때 사용합니다. 변수 값 자체의 크기를 기반으로 계산되기 때문에, 이상치(Outlier)의 영향을 많이 받는다는 특징이 있습니다.
-	결과 및 해석: 이 계수는 $-1$에서 $+1$ 사이의 값을 가지며, 값이 $1$에 가까울수록 강한 양의 선형 관계, $-1$에 가까울수록 강한 음의 선형 관계를 의미합니다. $0$에 가까우면 선형 관계가 거의 없다는 뜻입니다.

##  스피어만 상관계수 (Spearman Rank Correlation Coefficient, $\rho$)
-	스피어만 상관계수는 두 변수 $X$와 $Y$의 순위(Rank) 간의 **단조 관계(Monotonic Relationship)**의 강도와 방향을 측정하는 비모수적 방법입니다.
-	원인 및 사용 조건: 변수 자체가 **서열형 데이터(Ordinal Scale)**이거나, 연속형 데이터이더라도 정규성 가정을 만족하지 못하거나 이상치가 심할 때, 또는 관계가 선형이 아닌 단조 관계(한 변수가 증가할 때 다른 변수도 일관되게 증가하거나 감소하는 관계)일 때 피어슨 상관계수 대신 사용합니다. 변수 값 대신 순위 정보만을 활용하여 계산합니다.
-	결과 및 해석: 이 계수 역시 $-1$에서 $+1$ 사이의 값을 가지며, $1$에 가까울수록 순위가 완벽하게 일치하는 양의 단조 관계, $-1$에 가까울수록 순위가 반대로 일치하는 음의 단조 관계를 의미합니다. 순위를 사용하기 때문에 피어슨 계수에 비해 이상치에 덜 민감하다는 장점이 있습니다.
"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.model_selection import train_test_split

# =======================
# 1. 데이터 로드
# =======================
train = pd.read_csv("/content/train.csv", sep=",")
test = pd.read_csv("/content/test.csv", sep=",")

X = train.drop(columns=["ID", "support_needs"])
y = train["support_needs"]

X_test = test.drop(columns=["ID"])

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Head of train:")
display(train.head())

print("\nHead of test:")
display(test.head())

print("\nHead of X:")
display(X.head())

print("\nHead of y:")
display(y.head())

print("\nHead of X_train:")
display(X_train.head())

print("\nHead of X_valid:")
display(X_valid.head())

print("\nHead of y_train:")
display(y_train.head())

print("\nHead of y_valid:")
display(y_valid.head())

"""## 2. kmeans를 통한 클러스터 파생변수 추가

- 2-1. 원인: 클러스터링을 위한 데이터 준비
  - K-평균 알고리즘은 거리 기반으로 작동하기 때문에, 각 피처(Feature)의 스케일(Scale)이 다르면 특정 피처의 영향력이 과도하게 커지는 문제가 발생합니다. 따라서 클러스터링을 수행하기 전, 반드시 데이터를 **표준화(Standard Scaling)**하는 과정이 필요합니다.
- 2-2. 결과: 클러스터 파생변수 생성 코드
  - 아래 코드는 예시 연속형 변수(Feature_A, Feature_B)를 사용해 고객을 4개의 그룹으로 분류하고, 그 결과를 Cluster_ID라는 새로운 컬럼으로 데이터프레임(df)에 추가하는 과정입니다.

"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

# =======================================================
# 1. 클러스터링에 사용할 피처 선택 및 데이터 통합
# =======================================================

# 범주형 변수는 이 단계에서 제외, 클러스터링 피처 선택 (수치형 변수만)
# 모든 데이터셋을 합쳐서 (Train + Validation + Test) 클러스터링에 사용할 피처를 준비합니다.
# Object 타입(문자열/범주형) 및 Target 변수(support_needs)는 제외하고 수치형 변수만 사용합니다.
# ID는 이미 drop되었으므로 고려하지 않습니다.
# 비지도 학습이므로, 별도의 Target도 필요하지 않음.

# =======================================================
# 1. 클러스터링에 사용할 피처 선택 및 데이터 통합 (인덱스 초기화)
# =======================================================
CLUSTER_FEATURES = ['age', 'tenure', 'frequent', 'payment_interval', 'contract_length', 'after_interaction']

# 클러스터링 수행을 위해 세트들을 통합하고 인덱스를 초기화합니다.
# 인덱스 초기화를 통해 중복 레이블 문제를 근본적으로 해결합니다.

# 원본 인덱스 정보를 보존하기 위한 준비
train_idx = X_train.index
valid_idx = X_valid.index
test_idx = X_test.index

# 클러스터링에 사용할 데이터만 모으고 인덱스를 0부터 다시 시작하도록 초기화합니다.
X_combined_data = pd.concat([X_train[CLUSTER_FEATURES],
                             X_valid[CLUSTER_FEATURES],
                             X_test[CLUSTER_FEATURES]],
                            axis=0).reset_index(drop=True)

# =======================================================
# 2. 표준화 (Scaling) 수행 (수정된 부분: 인덱스 초기화된 데이터 사용)
# =======================================================
scaler = StandardScaler()

# 결측치 처리 (X_combined_data를 기준으로 처리)
X_combined_filled = X_combined_data.fillna(X_combined_data.mean())

# X_train 부분만 슬라이싱하여 Scaling 학습 (Data Leakage 방지)
train_size = len(X_train)
valid_size = len(X_valid)

X_train_part = X_combined_filled.iloc[:train_size]
X_valid_part = X_combined_filled.iloc[train_size : train_size + valid_size]
X_test_part = X_combined_filled.iloc[train_size + valid_size :]


# (1) X_train_part에 fit_transform 후, 전체에 transform 적용
X_train_scaled = scaler.fit_transform(X_train_part)
X_combined_scaled = scaler.transform(X_combined_filled)


# =======================================================
# 3. K-Means 모델 학습 및 클러스터 라벨링
# =======================================================
K = 5
kmeans = KMeans(n_clusters=K,
                random_state=42,
                n_init='auto',
                tol=1e-04)

# 학습 데이터셋(X_train_scaled)을 기준으로 클러스터 모델 학습
kmeans.fit(X_train_scaled)

# 통합 데이터셋에 클러스터 예측 라벨을 부여
cluster_labels_combined = kmeans.predict(X_combined_scaled)

# =======================================================
# 4. 결과: 클러스터 ID 파생변수 추가 (수정된 부분: 인덱스 초기화된 데이터프레임 이용)
# =======================================================

# 클러스터 라벨을 인덱스가 초기화된 데이터프레임으로 생성
df_combined_cluster = pd.DataFrame(cluster_labels_combined, columns=['Cluster_ID'])

# 각 분할된 데이터셋 크기에 맞게 클러스터 ID를 슬라이싱
cluster_train = df_combined_cluster.iloc[:train_size]['Cluster_ID']
cluster_valid = df_combined_cluster.iloc[train_size : train_size + valid_size]['Cluster_ID']
cluster_test = df_combined_cluster.iloc[train_size + valid_size :]['Cluster_ID']

# 원본 데이터프레임(X_train, X_valid, X_test)에 새로운 Cluster_ID를 할당
# 이 때, 할당되는 Cluster_ID의 인덱스를 원본 데이터프레임의 인덱스에 맞춥니다.
X_train['Cluster_ID'] = cluster_train.values
X_valid['Cluster_ID'] = cluster_valid.values
X_test['Cluster_ID'] = cluster_test.values

X_train['Cluster_ID'] = X_train['Cluster_ID'].astype('category')
X_valid['Cluster_ID'] = X_valid['Cluster_ID'].astype('category')
X_test['Cluster_ID'] = X_test['Cluster_ID'].astype('category')

print(f"✅ K-Means 클러스터링이 완료되었으며, K={K}인 'Cluster_ID' 파생변수가 중복 인덱스 오류 없이 추가되었습니다.")
print("\n[X_train의 Cluster_ID 분포]")
print(X_train['Cluster_ID'].value_counts().sort_index())

"""- 클러스터의 분포가 대체적으로 균등하여 양호한 분포로 판단

### 3. 파이캐럿 AutoML을 돌려서 상위 3개 모델을 선정
1. PyCaret을 사용한 AutoML 코드 정리
   - 1-1. 원인: PyCaret 환경 설정 및 자동 전처리
     - PyCaret의 setup 함수는 데이터프레임과 타겟 변수 이름을 입력받아 환경을 초기화하고, 내부적으로 데이터 분할(Train/Test Split), 범주형 변수 인코딩, 결측치 처리 등 복잡한 전처리 파이프라인을 자동으로 구축합니다. 이 과정이 선행되어야 compare_models 함수를 사용할 수 있습니다.

   - 1-2. 결과: 상위 3개 모델 선정 코드
     - 아래 코드는 mathbf{X_train}과 mathbf{y_train}을 학습 데이터로 통합하여 사용하고, mathbf{support_needs}를 예측하는 데 가장 우수한 상위 3개 모델을 선정합니다.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pycaret
# Pycaret지원되는 파이썬 런타임 유형으로 변경해야함(2025.07 - 3.11.14)

import pandas as pd
from pycaret.classification import * # pycaret 라이브러리에서 classification 모듈을 가져옵니다.

# =======================================================
# 1. 학습용 데이터셋 통합
# =======================================================
# X_train과 y_train을 하나의 데이터프레임으로 결합합니다.
# PyCaret의 setup 함수는 전체 데이터프레임을 요구합니다.
train_data_for_pycaret = X_train.copy()
train_data_for_pycaret['support_needs'] = y_train

print(f"PyCaret 학습 데이터 크기: {train_data_for_pycaret.shape}")

# =======================================================
# 2. PyCaret 환경 설정 (setup)
# =======================================================
# setup() 함수는 PyCaret 환경을 초기화하고 데이터 파이프라인을 구축합니다.
# Target Type: support_needs가 여러 범주를 가지므로 Multi-class classification으로 자동 인식됩니다.
# session_id: 재현성을 위해 고정합니다.
# categorical_features: 명시적으로 범주형 변수를 지정하여 정확한 인코딩을 유도합니다.
#                       (Cluster_ID는 이전 단계에서 category 타입으로 지정했으나, 명시적으로 지정해줍니다.)

# 범주형 변수 목록 (Cluster_ID 포함)
CATEGORICAL_FEATURES = ['gender', 'subscription_type', 'Cluster_ID']

clf_setup = setup(data = train_data_for_pycaret,
                  target = 'support_needs',
                  session_id = 42,
                  categorical_features = CATEGORICAL_FEATURES,
                  # normalize=True, # 스케일링은 K-Means 단계에서 이미 수행했으므로 선택적으로 사용합니다.
                  fold = 5, # 교차 검증 폴드 수를 5로 설정 (기본값은 10)
                  n_jobs = -1, # 가능한 모든 코어 사용
                  verbose = True) # 설정 과정을 출력합니다.

# =======================================================
# 3. 모델 비교 및 상위 3개 모델 선정 (compare_models)
# =======================================================
# compare_models() 함수는 PyCaret의 모든 모델을 교차 검증으로 학습하고 비교합니다.
# n_select=3: 상위 3개 모델을 리스트로 반환하도록 설정합니다.
# sort='Accuracy' 또는 'F1': 모델 순위 기준이 됩니다. (이 다중 분류 문제에서는 'F1' 또는 'Accuracy'가 일반적)

top3_models = compare_models(n_select=3,
                             sort='F1')

print("\n\n✅ PyCaret AutoML을 통해 선정된 상위 3개 모델 목록 (F1 Score 기준):")
print(top3_models)

"""### 4. catBoost를 블렌더 모델로 선정하여 전방 모델은 2번 상위모델 3개로 배치 = 스택킹
- 선정된 상위 3개 모델(lightgbm, xgboost, rf)을 사용하여 **CatBoost를 메타 모델(Meta Model, 또는 전방 모델)**로 배치하고 스태킹(Stacking) 앙상블을 진행
"""

# 전방(Base) 모델 학습 및 선정

# =======================================================
# 1. 상위 3개 모델 생성 (Base Estimators)
# =======================================================

# 1위: Light Gradient Boosting Machine (lightgbm)
lgbm = create_model('lightgbm', fold=5)
# 2위: Extreme Gradient Boosting (xgboost)
xgb = create_model('xgboost', fold=5)
# 3위: Random Forest Classifier (rf)
rf = create_model('rf', fold=5)

# 상위 3개 모델을 리스트로 묶습니다. (이들이 Stacker의 '입력' 역할을 합니다)
base_models = [lgbm, xgb, rf]

print("✅ 상위 3개 기반 모델 학습 완료.")

# Commented out IPython magic to ensure Python compatibility.
# %pip install catboost

# CatBoost 메타 모델 설정 및 Stacking 진행

# =======================================================
# 2. CatBoost 모델 생성 (Meta Model / Final Estimator)
# =======================================================
# CatBoost Classifier를 메타 모델로 생성합니다.
# 'catboost'는 PyCaret에서 'catboost'라는 ID로 사용됩니다.
# (이 때, CatBoost는 PyCaret의 setup 과정에서 자동으로 설치되거나 수동 설치가 필요할 수 있습니다.)

catb = create_model('catboost', fold=5, verbose=False) # 상세 출력은 끄고 생성


# =======================================================
# 3. Stacking 앙상블 모델 생성
# =======================================================

# stack_models 함수를 사용하여 Stacking 앙상블을 수행합니다.
# estimator_list: 상위 3개 모델 (입력 모델)
# meta_model: CatBoost (최종 결합 모델)

# 참고: 이 과정은 시간이 다소 소요될 수 있습니다.
stacker_catb = stack_models(estimator_list = base_models,
                            meta_model = catb,
                            fold = 5)

print("\n\n✅ CatBoost를 메타 모델로 사용한 Stacking 앙상블 모델 학습 완료.")

# (데이터 로드, Cluster_ID 추가, PyCaret setup이 모두 완료된 후 실행)

from pycaret.classification import create_model, stack_models

# 1. 상위 3개 기반 모델 생성 (Base Estimators)
lgbm = create_model('lightgbm', fold=5)
xgb = create_model('xgboost', fold=5)
rf = create_model('rf', fold=5)
base_models = [lgbm, xgb, rf]

# 2. CatBoost 모델 생성 (Meta Model / Final Estimator)
catb = create_model('catboost', fold=5, verbose=False)

# 3. Stacking 앙상블 모델 생성
stacker_catb = stack_models(estimator_list = base_models,
                            meta_model = catb,
                            fold = 5)

print("\n\n✅ Stacking 앙상블 모델 학습 성공!")

"""### 고찰: Stacking 모델의 효과 분석
-	2-1. 원인: Stacking의 기대치 미달 (F1 Score 기준)
- 최고 단일 모델: LightGBM이 가장 높은 **Accuracy (0.5278)**와 **F1 Score (0.4812)**를 기록했습니다.
- Stacking 모델: Stacking 모델은 **Accuracy (0.5156)**와 **F1 Score (0.4770)**를 기록하여, LightGBM 단일 모델보다 성능이 낮게 나왔습니다.
#### 이유: Stacking은 일반적으로 기반 모델들의 약점을 보완하여 성능을 향상시키지만, 현재 결과는 그렇지 못했습니다. 이는 다음 중 하나 이상의 원인 때문일 수 있습니다.
-	기반 모델의 다양성 부족: 상위 3개 모델 중 LightGBM과 XGBoost가 모두 Gradient Boosting 계열이라서 모델들이 서로 유사한 오류를 만들 가능성이 높았습니다.
-	기반 모델 및 메타 모델의 비최적화: 모든 모델이 하이퍼파라미터 튜닝(Tuning) 없이 기본 파라미터로만 학습되었기 때문에, 각 모델의 잠재력을 완전히 발휘하지 못했을 수 있습니다. 특히 CatBoost 메타 모델이 기반 모델들의 예측을 효과적으로 조합하도록 학습되지 않았을 수 있습니다.
#### AUC 관점에서의 긍정적 요소
-	Stacking 모델의 **AUC (0.6696)**는 Random Forest (0.6554)나 XGBoost (0.6600)보다 높습니다. AUC는 모델이 클래스를 구별하는 능력(Ranking)을 나타내므로, 잠재적으로 튜닝을 통해 개선될 여지가 있음을 시사합니다.


"""