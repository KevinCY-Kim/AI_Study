---
base_model: unsloth/llama-3.2-1b-bnb-4bit
library_name: peft
pipeline_tag: text-generation
tags:
- base_model:adapter:unsloth/llama-3.2-1b-bnb-4bit
- lora
- sft
- transformers
- trl
- unsloth
---

# π§  μ›°λ‹μ¤ μ±—λ΄‡ LLM νμΈνλ‹ μ‹¤μµ

## ν”„λ΅μ νΈ κ°μ”
- **λ©μ **: μ›°λ‹μ¤ μ°μΈμ¦ λ°μ΄ν„°μ…‹ κΈ°λ° LLM(unsloth/llama-3.2-1b-bnb-4bit) νμΈνλ‹ λ° μ±—λ΄‡ μ‹¤ν—
- **μ£Όμ” λ‚΄μ©**: λ°μ΄ν„° μ „μ²λ¦¬, νμΈνλ‹, μ €μ¥, μ¶”λ΅ , ν‰κ°€
- **λ°μ΄ν„°**: μ›°λ‹μ¤1.csv

## μ£Όμ” κΈ°λ¥ λ° μ½”λ“

### 1. λ°μ΄ν„° λ΅λ“
```python
import pandas as pd
df = pd.read_csv("μ›°λ‹μ¤1.csv", encoding="utf-8")
df.head()
```

### 2. λ¨λΈ λ° ν† ν¬λ‚μ΄μ € λ΅λ“ (Unsloth)
```python
from unsloth import FastLanguageModel
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/Llama-3.2-1B-bnb-4bit",
    max_seq_length = 2048,
    dtype = None,
    load_in_4bit = True
)
```

### 3. νμΈνλ‹(PEFT)
```python
# PEFT(νλΌλ―Έν„° ν¨μ¨μ  νμΈνλ‹) μ„¤μ • λ° ν•™μµ μ½”λ“ (μμ‹)
# ... (μ‹¤μ  ν•™μµ μ½”λ“/ν•μ΄νΌνλΌλ―Έν„°λ” λ…ΈνΈλ¶ μ°Έκ³ )
```

### 4. μ €μ¥ λ° μ¶”λ΅ 
```python
# λ¨λΈ μ €μ¥
model.save_pretrained("μ›°λ‹μ¤1_adapter")
# μ¶”λ΅  μμ‹
from transformers import pipeline
generator = pipeline("text-generation", model=model, tokenizer=tokenizer, device="cuda")
output = generator("μ›°λ‹μ¤ μ±—λ΄‡μ—κ² μ§λ¬Έ", max_new_tokens=128)
print(output)
```

### 5. ν‰κ°€ λ° κ²°κ³Ό
- νμΈνλ‹λ λ¨λΈμ μ„±λ¥, μμ‹ λ‹µλ³€, ν‰κ°€ κ²°κ³Ό λ“±μ€ λ…ΈνΈλ¶/μ‹¤ν— λ΅κ·Έ μ°Έκ³ 

---

## μ°Έκ³ /μ‹¤ν–‰ λ°©λ²•
- Jupyterμ—μ„ νμΈνλ‹/μ¶”λ΅  μ½”λ“ μ‹¤ν–‰
- λ°μ΄ν„°: μ›°λ‹μ¤1.csv

## μ£Όμ” μ½”λ“/λ…ΈνΈλ¶
- [μ›°λ‹μ¤_κµμ²΄μ‚¬λ‚΄κ·μ •.ipynb](../μ‚¬λ‚΄κ·μ •μ±—λ΄‡/μ›°λ‹μ¤_κµμ²΄μ‚¬λ‚΄κ·μ •.ipynb)
- [llamaνμΈνλ‹κ³Όν“¨μƒ·ν”„λ΅¬ν”„νΈ_RAG.ipynb](../../llamaνμΈνλ‹κ³Όν“¨μƒ·ν”„λ΅¬ν”„νΈ/llamaνμΈνλ‹κ³Όν“¨μƒ·ν”„λ΅¬ν”„νΈ_RAG.ipynb)