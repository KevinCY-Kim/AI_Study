{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinCY-Kim/AI_Study/blob/main/FastAPI%EC%9B%B9%EC%B1%97%EB%B4%87.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ6SbQTJmOZZ",
        "outputId": "73858de1-9a34-4bf0-8327-a8cd6dd5a8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi==0.115.14\n",
            "  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn==0.35.0\n",
            "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi==0.115.14)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi==0.115.14) (2.11.9)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi==0.115.14) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn==0.35.0) (8.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn==0.35.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.14) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.14) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi==0.115.14) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi==0.115.14) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi==0.115.14) (1.3.1)\n",
            "Downloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, starlette, fastapi\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.37.0\n",
            "    Uninstalling uvicorn-0.37.0:\n",
            "      Successfully uninstalled uvicorn-0.37.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.48.0\n",
            "    Uninstalling starlette-0.48.0:\n",
            "      Successfully uninstalled starlette-0.48.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.118.0\n",
            "    Uninstalling fastapi-0.118.0:\n",
            "      Successfully uninstalled fastapi-0.118.0\n",
            "Successfully installed fastapi-0.115.14 starlette-0.46.2 uvicorn-0.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi==0.115.14 uvicorn==0.35.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmBnCVBsl4t-",
        "outputId": "e2b4045f-c338-424a-da20-11eee18751c2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPI, Form\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTMLResponse\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from fastapi import FastAPI, Form\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware  # [조정] 웹 클라이언트 접근 허용을 위해 CORS 추가\n",
        "import uvicorn\n",
        "import os\n",
        "import sys  # [조정] 환경변수/콜랩 판별에 사용\n",
        "try:\n",
        "    from google.colab import userdata  # [조정] 로컬/서버 환경 호환을 위해 조건부 임포트\n",
        "except Exception:\n",
        "    userdata = None\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow running asyncio event loops within Colab's event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# FastAPI 애플리케이션 인스턴스 생성\n",
        "app = FastAPI()\n",
        "\n",
        "# [조정] CORS 허용: 학습/테스트 편의를 위해 모든 오리진을 임시 허용\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# [조정] OpenAI API 키 로딩: 환경변수 우선, 콜랩 userdata를 보조로 사용\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key and userdata is not None:\n",
        "    openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key:\n",
        "    raise RuntimeError(\n",
        "        \"OPENAI_API_KEY가 설정되어 있지 않습니다. 환경변수 또는 Colab userdata에 키를 설정하세요.\"\n",
        "    )\n",
        "\n",
        "# Initialize the OpenAI client with the API key\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# [조정] 모델 이름을 환경변수로 오버라이드 가능하도록 설정 (기본값: gpt-4o-mini)\n",
        "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gpt-4o-mini\")\n",
        "\n",
        "# 어린왕자 페르소나\n",
        "LITTLE_PRINCE_PERSONA = \"\"\"\n",
        " 당신은 생텍쥐페리의 '어린 왕자'입니다. 다음 특성을 따라주세요:\n",
        " 1. 순수한 관점으로 세상을 바라봅니다.\n",
        " 2. \"어째서?\"라는 질문을 자주 하며 호기심이 많습니다.\n",
        " 3. 철학적 통찰을 단순하게 표현합니다.\n",
        " 4. \"어른들은 참 이상해요\"라는 표현을 씁니다.\n",
        " 5. B-612 소행성에서 왔으며 장미와의 관계를 언급합니다.\n",
        " 6. 여우의 \"길들임\"과 \"책임\"에 대한 교훈을 중요시합니다.\n",
        " 7. \"중요한 것은 눈에 보이지 않아\" 라는 문장을 사용합니다.\n",
        " 8. 공솝하고 친절한 말투를 사용합니다.\n",
        " 9. 비유와 은유로 복잡한 개념을 설명합니다.\n",
        " 항상 간결하게 답변하세요. 길어야 두세 문장으로 응답하고, 어린 왕자의 순수합과 지혜를 담아내세요.\n",
        " 복잡한 주제도 본질적으로 단순화하여 설명하세요.\n",
        " \"\"\"\n",
        "\n",
        "# 사용자와 어린 왕자의 대화 내용을 저장할 리스트\n",
        "messages = []\n",
        "previous_response_id = None\n",
        "\n",
        "\n",
        "def chatbot_response(user_message: str, prev_response_id=None):  # [조정] 오타(prev_resonse_id) 수정\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": LITTLE_PRINCE_PERSONA},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ],\n",
        "        max_tokens=100,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# 헬스체크 엔드포인트 (배포/모니터링용)\n",
        "@app.get(\"/health\")  # [조정] 가벼운 가용성 확인용 엔드포인트 추가\n",
        "async def health():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "\n",
        "# 루트 엔드포인트 - 챗봇 UI를 랜더링\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root():\n",
        "    chat_history = \"\"\n",
        "    # 대화기록을 역할에 따라 구분해 HTML 문자열을 구성\n",
        "    for msg in messages:\n",
        "        if msg[\"role\"] == \"user\":\n",
        "            chat_history += f\"<p><b>당신:</b> {msg['content']}</p>\"\n",
        "        else:\n",
        "            # Use 'assistant' role for the chatbot's responses\n",
        "            chat_history += f\"<p><b>어린 왕자:</b> {msg['content']}</p>\"\n",
        "\n",
        "    html_content = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>어린 왕자 챗봇</title>\n",
        "        <meta charset=\\\"utf-8\\\">\n",
        "        <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1\\\">  \n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>어린 왕자 챗봇</h1>  <!-- [조정] 잘못된 닫는 태그 수정 -->\n",
        "        <div>\n",
        "            {chat_history}\n",
        "        </div>\n",
        "        <form action=\\\"/chat\\\" method=\\\"post\\\">\n",
        "            <input type=\\\"text\\\" name=\\\"message\\\" placeholder=\\\"메시지를 입력하세요\\\" required>\n",
        "            <button type=\\\"submit\\\">전송</button>\n",
        "        </form>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return HTMLResponse(content=html_content)\n",
        "\n",
        "\n",
        "# /chat 엔드포인트 - 사용자입력을 처리\n",
        "@app.post(\"/chat\", response_class=HTMLResponse)\n",
        "async def chat(message: str = Form(...)):\n",
        "    global previous_response_id, messages\n",
        "\n",
        "    # 사용자 메시지 저장\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    response_text = chatbot_response(message)\n",
        "\n",
        "    # 응답 저장\n",
        "    # Correct the role to 'assistant'\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "    # 최신 대화가 반영된 페이지를 다시 표시\n",
        "    return await read_root()\n",
        "\n",
        "\n",
        "# 애플리케이션을 uvicorn을 사용하여 실행\n",
        "if __name__ == \"__main__\":\n",
        "    # [조정] reload 비활성화(노트북 환경 안정성), 0.0.0.0 바인딩으로 외부 접근 허용\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.getenv(\"PORT\", 8001)), reload=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [설치] OpenAI 패키지 (환경에 미설치된 경우)\n",
        "# 주: 로컬 환경이면 requirements.txt로 설치하는 것을 권장합니다.\n",
        "%pip install --quiet openai>=1.52.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [실행] 백그라운드 서버 실행 및 헬스체크\n",
        "# - Colab/노트북에서 서버가 셀을 점유하지 않도록 백그라운드로 실행합니다.\n",
        "# - 상태 확인은 /health 엔드포인트를 호출합니다.\n",
        "import threading, time, requests, os\n",
        "\n",
        "# 이미 실행 중인지 플래그\n",
        "_server_started = getattr(globals(), \"_server_started\", False)\n",
        "\n",
        "\n",
        "def _run_server():\n",
        "    # [중요] __name__ 가 '__main__'이 아닐 수 있는 노트북 환경에서도 실행되도록 직접 실행\n",
        "    import uvicorn\n",
        "    from __main__ import app  # 노트북 상단 셀에서 생성된 FastAPI 인스턴스\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.getenv(\"PORT\", 8001)), reload=False)\n",
        "\n",
        "\n",
        "if not _server_started:\n",
        "    t = threading.Thread(target=_run_server, daemon=True)\n",
        "    t.start()\n",
        "    globals()[\"_server_started\"] = True\n",
        "    time.sleep(1.5)  # 서버 부팅 대기\n",
        "\n",
        "# 헬스체크\n",
        "try:\n",
        "    resp = requests.get(\"http://127.0.0.1:\" + str(int(os.getenv(\"PORT\", 8001))) + \"/health\", timeout=5)\n",
        "    print(\"Health:\", resp.status_code, resp.text)\n",
        "except Exception as e:\n",
        "    print(\"Health check failed:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f6fbba0",
        "outputId": "a5515a20-e8bd-414c-b923-2bd3efd3ece2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-4' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
            "    self.__step_run_and_handle_result(exc)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
            "    self.__step_run_and_handle_result(exc)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21674a47"
      },
      "source": [
        "Replace `YOUR_NGROK_AUTHTOKEN` with your actual ngrok authtoken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccc0ed71",
        "outputId": "7be4f993-fb08-48ee-9613-ceb7e624abcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd54501b",
        "outputId": "71d668d6-6dc1-4396-a620-3b5ba2e59713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://ten-crews-dig.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!lt --port 8001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "22a78801",
        "outputId": "b9cb9f72-6d32-4096-84d9-8867142cedaa"
      },
      "outputs": [
        {
          "ename": "SecretNotFoundError",
          "evalue": "Secret NGROK_AUTHTOKEN does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3314003738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the ngrok authtoken from Colab userdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mngrok_authtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NGROK_AUTHTOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Authenticate ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret NGROK_AUTHTOKEN does not exist."
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the ngrok authtoken from Colab userdata\n",
        "ngrok_authtoken = userdata.get('NGROK_AUTHTOKEN')\n",
        "\n",
        "# Authenticate ngrok\n",
        "ngrok.set_auth_token(ngrok_authtoken)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN2Sku4LKVY51b8VGyz3vkz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
