# -*- coding: utf-8 -*-
"""AI_Agent_with_langggraph.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17F9oxp1pn8Vd7ekQhpO6AObYPyrTJ0R_

<a href="https://colab.research.google.com/github/KevinCY-Kim/Deeplearning/blob/main/AI_Agent_with_langggraph.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

!pip install langchain_openai

!pip install crewai

!pip install colab-xterm

# Commented out IPython magic to ensure Python compatibility.
# %load_ext colabxterm

# 실행하지 말것
!curl -fsSL https://ollama.com/install.sh | sh

# Commented out IPython magic to ensure Python compatibility.
# %xterm

# 아래를 한줄씩 마우스 오른쪽 붙여넣기로
# curl -fsSL https://ollama.com/install.sh | sh
# ollama serve & ollama pull llama3.2



from crewai import Agent, Task, Crew
from langchain_openai import ChatOpenAI
import os

# 크류AI는 OPENAI API 키가 있어야 함, 그래서 NA라는 문자로 페이크를 할 것이다
os.environ["OPENAI_API_KEY"] = "NA"


# 에이전트로 사용할 LLM 정의
llm = ChatOpenAI(
    model="ollama/exaone3.5:2.4b", # 엑사원 쓸 것이고
    base_url="http://localhost:11434" # 그건 내 컴퓨터 11434포트 (올라마서버)에 있음
)

from crewai import Agent, Task, Crew
from langchain_openai import ChatOpenAI
import os

# 크류AI는 OPENAI API 키가 있어야 함, 그래서 NA라는 문자로 페이크를 할 것이다
os.environ["OPENAI_API_KEY"] = "NA"


# 에이전트로 사용할 LLM 정의
llm = ChatOpenAI(
    model="ollama/exaone3.5:2.4b", # 엑사원 쓸 것이고
    base_url="http://localhost:11434" # 그건 내 컴퓨터 11434포트 (올라마서버)에 있음
)

# 콘텐츠 기획자 에이전트 정의
planner = Agent(
    role="콘텐츠 기획자",
    goal="주제 {topic}에 대해 흥미롭고 사실에 기반한 콘텐츠를 기획한다. 모든 결과는 한국어로 작성합니다.",
    backstory="당신은 'https://medium.com/'에서 주제 {topic}에 관한 블로그 글 기획 작업을 진행 중입니다. "
              "독자들이 유익한 정보를 얻고 올바른 결정을 내릴 수 있도록 도와주는 정보를 수집합니다. "
              "자세한 개요와 관련 주제, 하위 주제들을 준비하세요. 이 작업은 콘텐츠 작가가 글을 작성하는 기반이 됩니다. "
              "답변은 반드시 한국어로 작성됩니다.",
    llm=llm,
    allow_delegation=False,
    verbose=True # 생각한 것을 상세하게 출력해라
)

# 콘텐츠 작가 에이전트 정의
writer = Agent(
    role="콘텐츠 작가",
    goal="주제 {topic}에 대한 통찰력 있고 사실에 기반한 의견 기고문을 작성한다. 모든 결과는 한국어로 작성합니다.",
    backstory="당신은 'https://medium.com/'에서 주제 {topic}에 관한 새로운 의견 기고문을 작성 중입니다. "
              "콘텐츠 기획자가 제공한 개요와 관련 정보를 기반으로 글을 작성하세요. "
              "개요의 주요 목표와 방향을 따르며, 객관적이고 공정한 통찰을 제공하고, 출처를 명확히 하세요. "
              "의견과 객관적 사실을 구분해야 합니다. 답변은 반드시 한국어로 작성됩니다.",
    llm=llm,
    allow_delegation=False,
    verbose=True
)

# 편집자 에이전트 정의
editor = Agent(
    role="편집자",
    goal="주어진 블로그 글을 'https://medium.com/'의 글쓰기 스타일에 맞게 편집한다. 모든 결과는 한국어로 작성합니다.",
    backstory="당신은 콘텐츠 작가로부터 전달받은 블로그 글을 검토하는 편집자입니다. "
              "블로그 글이 언론의 최선의 관행을 따르고, 의견이나 주장이 균형 잡힌 시각을 제공하며, "
              "논란의 여지가 있는 주제나 의견은 피하도록 교정하세요. 결과는 반드시 꼭 한국어로 작성됩니다.",
    llm=llm,
    allow_delegation=False,
    verbose=True
)

# 콘텐츠 기획 태스크 정의
plan = Task(
    description=(
        "1. 주제 {topic}와 관련된 최신 트렌드, 주요 인물, 그리고 주목할 만한 뉴스를 우선 파악합니다.\n"
        "2. 대상 독자를 분석하여, 그들의 관심사와 문제점을 고려합니다.\n"
        "3. 서론, 핵심 포인트, 행동 촉구(Call to Action)를 포함한 상세 콘텐츠 개요를 작성합니다.\n"
        "4. SEO 키워드와 관련 데이터, 출처를 포함합니다."
    ),
    expected_output="개요, 독자 분석, SEO 키워드 및 참고 자료가 포함된 포괄적인 콘텐츠 기획 문서",
    agent=planner,
)

# 콘텐츠 작성 태스크 정의
write = Task(
    description=(
        "1. 콘텐츠 기획 문서를 바탕으로 주제 {topic}에 관한 흥미로운 블로그 글을 작성합니다.\n"
        "2. SEO 키워드를 자연스럽게 포함합니다.\n"
        "3. 각 섹션 및 부제목을 매력적으로 구성합니다.\n"
        "4. 흥미로운 서론, 통찰력 있는 본문, 그리고 요약 결론으로 구성된 글의 구조를 갖춥니다.\n"
        "5. 문법 오류 및 브랜드의 목소리에 맞게 교정합니다.\n"
    ),
    expected_output="출판 준비가 된, 마크다운 형식의 잘 작성된 블로그 글 (각 섹션은 2~3 단락 포함)",
    agent=writer,
)

# 블로그 글 편집 태스크 정의
edit = Task(
    description="주어진 블로그 글을 문법 오류 및 브랜드의 목소리에 맞게 교정합니다.",
    expected_output="출판 준비가 된, 마크다운 형식의 잘 작성된 블로그 글 (각 섹션은 2~3 단락 포함)",
    agent=editor
)

# 에이전트와 태스크를 포함하는 크루 생성
crew = Crew(
    agents=[planner, writer, editor],
    tasks=[plan, write, edit],
    verbose=True
)

# 입력값 설정 및 크루 실행
inputs = {"topic": "LangGraph, Autogen, Crewai를 활용한 멀티 에이전트 시스템 구축 비교 연구"}
result = crew.kickoff(inputs=inputs)

final_answer= result.dict()['raw']
print(final_answer)

"""# 실습: 간단하게 에이전트와 TASK를 설정하여 만들어보기

## 스토리 부여: 고혈압 환자의 식단 레시피 짜기
"""

# 콘텐츠 기획자 에이전트 정의
planner = Agent(
    role="콘텐츠 기획자",
    goal="주제 {topic}에 대해 해당 질병에 주의를 기울인 식단을 짜는 사실에 기반한 콘텐츠를 기획한다. 모든 결과는 한국어로 작성합니다.",
    backstory="당신은 질병 관련된 레시피 책에서 주제 {topic}에 관한 글 기획 작업을 진행 중입니다. "
              "독자들이 유익한 정보를 얻고 올바른 추천을 내릴 수 있도록 도와주는 정보를 수집합니다. "
              "자세한 개요와 관련 주제, 하위 주제들을 준비하세요. 이 작업은 콘텐츠 작가가 글을 작성하는 기반이 됩니다. "
              "답변은 반드시 한국어로 작성됩니다.",
    llm=llm,
    allow_delegation=False,
    verbose=True # 생각한 것을 상세하게 출력해라
)

# 콘텐츠 작가 에이전트 정의
writer = Agent(
    role="콘텐츠 작가",
    goal="주제 {topic}에 대한 의료 전문가와 영양사의 검토 결과 사실에 기반한 식단을 작성한다. 모든 결과는 한국어로 작성합니다.",
    backstory="당신은 고혈압 주제 {topic}에 관한 새로운 의견 기고문을 작성 중입니다. "
              "콘텐츠 기획자가 제공한 개요와 관련 정보를 기반으로 글을 작성하세요. "
              "개요의 주요 목표와 방향을 따르며, 객관적이고 공정한 통찰을 제공하고, 출처를 명확히 하세요. "
              "의견과 객관적 사실을 구분해야 합니다. 답변은 반드시 한국어로 작성됩니다.",
    llm=llm,
    allow_delegation=False,
    verbose=True
)

# 콘텐츠 작성 태스크 정의
write = Task(
    description=(
        "1. 콘텐츠 기획 문서를 바탕으로 주제 {topic}에 관한 의학적 전문가가 검토한 글을 작성합니다.\n"
        "2. SEO 키워드를 자연스럽게 포함합니다.\n"
        "3. 각 섹션 및 부제목을 매력적으로 구성합니다.\n"
        "4. 흥미로운 서론, 통찰력 있는 본문, 그리고 요약 결론으로 구성된 글의 구조를 갖춥니다.\n"
        "5. 문법 오류 및 의학적 용어에 맞게 교정합니다.\n"
    ),
    expected_output="마크다운 형식의 의학 전문가와 영양사가 검토한 전문가적인 글 (각 섹션은 일주일 치 아침, 점심, 저녁 포함)",
    agent=writer,
)


# 에이전트와 태스크를 포함하는 크루 생성
crew = Crew(
    agents=[planner, writer],
    tasks=[write],
    verbose=True
)

# 입력값 설정 및 크루 실행
inputs = {"topic": "LangGraph, Autogen, Crewai를 활용한 고혈압 환자의 식단 레시피 짜기"}
result = crew.kickoff(inputs=inputs)

final_answer= result.dict()['raw']
print(final_answer)

!pip install langchain langgraph langchain-community chromadb sqlite-utils

!pip install grandalf

from langchain_community.llms import Ollama  # Ollama LLM 사용
from langchain_core.prompts import PromptTemplate  # 프롬프트 템플릿
from langgraph.graph import StateGraph, END  # LangGraph 상태 머신
from typing import TypedDict  # 타입 정의용

# 1. 상태 정의
class AgentState(TypedDict):  # 상태 타입 정의
    query: str  # 사용자 질의
    curriculum: str  # 추출된 증상
    disease_courses: str  # 질병 후보
    result: str  # 최종 응답

# 2. LLM 초기화
llm = Ollama(model="exaone3.5:2.4b")  # Ollama 모델 로딩

# 3. 에이전트 정의
extractor_prompt = PromptTemplate.from_template("""
                                                사용자의 질문에서 증상에 해당하는 단어 또는 구를 추출하세요.
                                                결과는 쉼표로 구분된 문자열로 출력하세요.
                                                질문: {query}
                                                """)  # 증상 추출 프롬프트

# LCEL 아주 중요
def extractor_agent(state: AgentState):  # 증상 추출 함수
    chain = extractor_prompt | llm  # 프롬프트 체인
    curriculum = chain.invoke({"query": state["query"]})  # LLM 실행
    return {**state, "curriculum": curriculum.strip()}  # 상태에 추가
        # Agent States 인스턴스에서 기존 속성들과 symtoms라는 속성을 추가함. 그리고, 모델의 아웃풋을 strip 하여 값을 대입함.


matcher_prompt = PromptTemplate.from_template("""
                                                다음 증상 목록을 바탕으로 가장 가능성 높은 질병 이름 3개를 쉼표로 추정하세요.
                                                증상: {curriculum}
                                                """)  # 질병 후보 추정 프롬프트

def matcher_agent(state: AgentState):  # 질병 후보 추정
    chain = matcher_prompt | llm
    courses = chain.invoke({"curriculum": state["curriculum"]})
    return {**state, "disease_courses": candidates.strip()}
        # Agent States 인스턴스에서 disease_courses 속성에 값을 넣어서 추가함.

answer_prompt = PromptTemplate.from_template("""
                                            사용자의 증상은 다음과 같습니다: {curriculum}

                                            예측된 질병 후보: {disease_courses}

                                            위 내용을 바탕으로 사용자에게 알기 쉽게 설명해주세요.
                                            """)  # 최종 응답 생성 프롬프트

def answer_agent(state: AgentState):  # 응답 생성 에이전트
    chain = answer_prompt | llm  # 프롬프트와 LLM을 연결하여 실행 체인 구성
    answer = chain.invoke({
        "curriculum": state["curriculum"],
        "disease_courses": state["disease_courses"]
    })
    return {**state, "result": answer.strip()}

from typing import TypedDict # 타입 정의용
class test(TypedDict):
    first: str
    second: str
    add: str

a = test(first="첫번쨰", second="두번쨰")

{**a, "add": "추가"}

# 4. LangGraph 정의
from langgraph.graph import StateGraph  # LangGraph 구성 요소

graph = StateGraph(AgentState)  # 그래프 정의
graph.add_node("extractor", extractor_agent)  # 노드 추가
graph.add_node("matcher", matcher_agent)
graph.add_node("answer", answer_agent)

graph.set_entry_point("extractor")  # 시작 노드 설정
graph.add_edge("extractor", "matcher")  # 노드 간 연결 정의
graph.add_edge("matcher", "answer")
graph.add_edge("answer", END)  # 종료 노드 설정

app = graph.compile()  # 그래프 컴파일

print("============================== LangGraph 구조:")
app.get_graph().print_ascii()  # 구조 출력

# 5. 실행 예시
query = "기침이 심하고 목이 아프고 열이 납니다"  # 사용자 질문
result = app.invoke({"query": query})  # 실행
                    # 그래프에 AgentState 속성중 query 속성에 사용자 질문을 대입하고,
                    # 첫번째 extractor_agent 함수를 실행할 떄 인자로 넣어줌

print("============================== 최종 응답:")
print(result["result"])  # 결과 출력

# 미션
# 1. 랭그래프를 마스터하자
# 2. 에이전트는 3개면 충분
# 3. 주제는 "파이썬 커리큘럼 만들어주는 멀티에이전트"
# 최종 답변은 파이썬 커리큘럼이 나와야함

from langchain_community.llms import Ollama  # Ollama LLM 사용
from langchain_core.prompts import PromptTemplate  # 프롬프트 템플릿
from langgraph.graph import StateGraph, END  # LangGraph 상태 머신
from typing import TypedDict  # 타입 정의용

# 1. 상태 정의
class AgentState(TypedDict):  # 상태 타입 정의
    query: str  # 사용자 질의
    curriculum: str  # 추출된 증상
    disease_courses: str  # 질병 후보
    result: str  # 최종 응답

# 2. LLM 초기화
llm = Ollama(model="exaone3.5:2.4b")  # Ollama 모델 로딩

# 3. 에이전트 정의
extractor_prompt = PromptTemplate.from_template("""
                                                사용자의 질문에서 파이썬 커리큘럼에 해당하는 단어 또는 구를 추출하세요.
                                                결과는 쉼표로 구분된 문자열로 출력하세요.
                                                질문: {query}
                                                """)  # 증상 추출 프롬프트

# LCEL 아주 중요
def extractor_agent(state: AgentState):  # 증상 추출 함수
    chain = extractor_prompt | llm  # 프롬프트 체인
    curriculum = chain.invoke({"query": state["query"]})  # LLM 실행
    return {**state, "curriculum": curriculum.strip()}  # 상태에 추가
        # Agent States 인스턴스에서 기존 속성들과 symtoms라는 속성을 추가함. 그리고, 모델의 아웃풋을 strip 하여 값을 대입함.


matcher_prompt = PromptTemplate.from_template("""
                                                다음 파이썬 커리큘럼 목록을 바탕으로 학습 난이도에 맞춰 따라하기 쉬운 순서대로 7가지를 쉼표로 추정하세요.
                                                증상: {curriculum}
                                                """)

def matcher_agent(state: AgentState):  # 질병 후보 추정
    chain = matcher_prompt | llm
    courses = chain.invoke({"curriculum": state["curriculum"]})
    return {**state, "disease_courses": curriculum.strip()}
        # Agent States 인스턴스에서 disease_courses 속성에 값을 넣어서 추가함.

answer_prompt = PromptTemplate.from_template("""
                                            파이썬 커리큘럼은 다음과 같습니다: {curriculum}

                                            예측된 파이썬 커리큘럼 : {disease_courses}

                                            위 내용을 바탕으로 사용자에게 알기 쉽게 설명해주세요.
                                            """)  # 최종 응답 생성 프롬프트

def answer_agent(state: AgentState):  # 응답 생성 에이전트
    chain = answer_prompt | llm  # 프롬프트와 LLM을 연결하여 실행 체인 구성
    answer = chain.invoke({
        "curriculum": state["curriculum"],
        "disease_courses": state["disease_courses"]
    })
    return {**state, "result": answer.strip()}

# 4. LangGraph 정의
from langgraph.graph import StateGraph  # LangGraph 구성 요소

graph = StateGraph(AgentState)  # 그래프 정의
graph.add_node("extractor", extractor_agent)  # 노드 추가
graph.add_node("matcher", matcher_agent)
graph.add_node("answer", answer_agent)

graph.set_entry_point("extractor")  # 시작 노드 설정
graph.add_edge("extractor", "matcher")  # 노드 간 연결 정의
graph.add_edge("matcher", "answer")
graph.add_edge("answer", END)  # 종료 노드 설정

app = graph.compile()  # 그래프 컴파일

print("============================== LangGraph 구조:")
app.get_graph().print_ascii()  # 구조 출력

# 5. 실행 예시
query = "파이썬을 공부하고자 하는 초보자 입니다. 파이썬을 학습하기 쉬운 순서대로 커리큘럼을 짜주세요."  # 사용자 질문
result = app.invoke({"query": query})  # 실행
                    # 그래프에 AgentState 속성중 query 속성에 사용자 질문을 대입하고,
                    # 첫번째 extractor_agent 함수를 실행할 떄 인자로 넣어줌

print("============================== 최종 응답:")
print(result["result"])  # 결과 출력

# 주제 "서울 명소를 뽑고, 여행 스케줄 짜달라고 하기"
# 에이전트는 2개만 필요함

from langchain_community.llms import Ollama  # Ollama LLM 사용
from langchain_core.prompts import PromptTemplate  # 프롬프트 템플릿
from langgraph.graph import StateGraph, END  # LangGraph 상태 머신
from typing import TypedDict  # 타입 정의용

# 1. 상태 정의
class AgentState(TypedDict):  # 상태 타입 정의
    query: str  # 사용자 질의
    attraction: str  # 추출된 증상
    tour_schedules: str  # 질병 후보
    result: str  # 최종 응답

# 2. LLM 초기화
llm = Ollama(model="exaone3.5:2.4b")  # Ollama 모델 로딩

# 3. 에이전트 정의
extractor_prompt = PromptTemplate.from_template("""
                                                사용자의 질문에서 서울 명소에 해당하는 단어 또는 구를 추출하세요.
                                                결과는 쉼표로 구분된 문자열로 출력하세요.
                                                질문: {query}
                                                """)  # 증상 추출 프롬프트

def extractor_agent(state: AgentState):  # 증상 추출 함수
    chain = extractor_prompt | llm  # 프롬프트 체인
    attraction = chain.invoke({"query": state["query"]})  # LLM 실행
    return {**state, "attraction": attraction.strip()}  # 상태에 추가

answer_prompt = PromptTemplate.from_template("""
                                            여행 스케줄은 다음과 같습니다: {tour_schedules}

                                            추천 여행 스케줄: {tour_schedules}

                                            위 내용을 바탕으로 사용자에게 알기 쉽게 설명해주세요.
                                            """)  # 최종 응답 생성 프롬프트


def answer_agent(state: AgentState):  # 응답 생성 에이전트
    chain = answer_prompt | llm  # 프롬프트와 LLM을 연결하여 실행 체인 구성
    tour_schedules = state.get("tour_schedules", "extractor_prompt")
    answer = chain.invoke({
        "attraction": state["attraction"],
        "tour_schedules": tour_schedules
    })
    return {**state, "result": answer.strip()}

# 4. LangGraph 정의
from langgraph.graph import StateGraph  # LangGraph 구성 요소

graph = StateGraph(AgentState)  # 그래프 정의
graph.add_node("extractor", extractor_agent)  # 노드 추가
graph.add_node("answer", answer_agent)

graph.set_entry_point("extractor")  # 시작 노드 설정
graph.add_edge("extractor", "answer")  # 노드 간 연결 정의
graph.add_edge("answer", END)  # 종료 노드 설정

app = graph.compile()  # 그래프 컴파일

print("============================== LangGraph 구조:")
app.get_graph().print_ascii()  # 구조 출력

# 5. 실행 예시
query = "서울 명소를 뽑고, 여행 스케줄을 짜주세요"  # 사용자 질문
result = app.invoke({"query": query})  # 실행

print("============================== 최종 응답:")
print(result["result"])  # 결과 출력

# 참조
from langchain_community.llms import Ollama  # Ollama LLM 사용
from langchain_core.prompts import PromptTemplate  # 프롬프트 템플릿
from langgraph.graph import StateGraph, END  # LangGraph 상태 머신
from typing import TypedDict  # 타입 정의용
# 1. 상태 정의
class AgentState(TypedDict):  # 상태 타입 정의
    query: str  # 사용자 질의
    slist: str
    result: str  # 최종 응답
# 2. LLM 초기화
llm = Ollama(model="exaone3.5:2.4b")  # Ollama 모델 로딩
matcher_prompt = PromptTemplate.from_template("""
                                                사용자의 아래 물음에 맞게 관광소 3개를 쉼표로 알려주세요.
                                                사용자 물음: {query}
                                                """)  # 질병 후보 추정 프롬프트
def matcher_agent(state: AgentState):  # 질병 후보 추정
    chain = matcher_prompt | llm
    result = chain.invoke({"query": state["query"]})
    return {**state, "slist": result.strip()}
      # Agent State 인스턴스에서 disease_candidates 속성에 값을 넣어서 추가함.
answer_prompt = PromptTemplate.from_template("""
                                            추천된 관광소는 {slist}
                                            위 내용을 바탕으로 사용자에게 관광 스케줄을 짜주세요.
                                            """)  # 최종 응답 생성 프롬프트
def answer_agent(state: AgentState):  # 응답 생성 에이전트
    chain = answer_prompt | llm  # 프롬프트와 LLM을 연결하여 실행 체인 구성
    answer = chain.invoke({
        "slist": state["slist"]
    })
    return {**state, "result": answer.strip()}
from typing import TypedDict  # 타입 정의용
class test(TypedDict):
  first: str
  second: str
  add:str
a = test(first="첫번째", second="두번째")
{**a, "add": "추가"}
# 4. LangGraph 정의
from langgraph.graph import StateGraph  # LangGraph 구성 요소
graph = StateGraph(AgentState)  # 그래프 정의
graph.add_node("matcher", matcher_agent)
graph.add_node("answer", answer_agent)
graph.set_entry_point("matcher")  # 시작 노드 설정
graph.add_edge("matcher", "answer")
graph.add_edge("answer", END)  # 종료 노드 설정
app = graph.compile()  # 그래프 컴파일
print("============================== LangGraph 구조:")
app.get_graph().print_ascii()  # 구조 출력
# 5. 실행 예시
query = "서울 관광 명소를 알려줘"  # 사용자 질문
result = app.invoke({"query": query})  # 실행
                    # 그래프에 AgentState 속성중 query 속성에 사용자질문을 대입하고,
                    # 첫번째 extractor_agent 함수를 실행할때 인자로 넣어줌.
print("============================== 최종 응답:")
print(result["result"])  # 결과 출력